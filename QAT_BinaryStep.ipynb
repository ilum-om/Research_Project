{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipgaw8VwPfAE"
   },
   "source": [
    "# Imports, functions and classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkXRKd8HrFcG"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3123909-6f2a-41b9-8545-28d6290350d7",
    "outputId": "8273f5a8-ebf0-49a6-d735-52218c7cb7f5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6964\\3185342628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import itertools\n",
    "import pandas as pd\n",
    "!pip install -q torchsummary\n",
    "from torchsummary import summary\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USbGLTxvdQdA",
    "outputId": "22f6c2cd-ee4c-40e5-fbd8-8f882f28f072"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3628\\1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opRUT0cJ0i_3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j4KlWvvrepV"
   },
   "source": [
    "## Adder dataloader\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "General adder to define dataloader automatically based on Nbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3582GaEMtd5d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def NAND(x, y):\n",
    "     if x == 0 and y == 0: return 1\n",
    "     if x == 0 and y == 1: return 1\n",
    "     if x == 1 and y == 0: return 1\n",
    "     if x == 1 and y == 1: return 0\n",
    "\n",
    "def NOT(x):\n",
    "     return NAND(x, x)\n",
    "\n",
    "def AND(x, y):\n",
    "     return NOT(NAND(x, y))\n",
    "\n",
    "def OR(x, y):\n",
    "     return NAND(NAND(x, x), NAND(y, y))\n",
    "\n",
    "def XOR(x, y):\n",
    "     return AND(OR(x, y),\n",
    "                NOT(AND(x, y)))\n",
    "\n",
    "def HALF(x, y):\n",
    "     carry = AND(x, y)\n",
    "     sum = XOR(x, y)\n",
    "     return (carry, sum)\n",
    "\n",
    "def FULL(x, y, carry_in):\n",
    "     carry1, sum1 = HALF(x, y)\n",
    "     carry2, sum2 = HALF(carry_in, sum1)\n",
    "     carry_out = OR(carry1, carry2)\n",
    "     return (carry_out, sum2)\n",
    "\n",
    "def ADDN(left, right, carry_in):\n",
    "    N = len(left)\n",
    "    sums = []\n",
    "    carry = carry_in\n",
    "\n",
    "    for i in range(N-1, -1, -1):\n",
    "        carry, sum_ = FULL(left[i], right[i], carry)\n",
    "        sums.insert(0, sum_)\n",
    "\n",
    "    return sums + [carry]\n",
    "\n",
    "\n",
    "def generate_adder_dataframe(N, add_constant=True, constant_value=1):\n",
    "    inputs = [\n",
    "        [*bin(i)[2:].zfill(N), *bin(j)[2:].zfill(N), carry_in]\n",
    "        for i in range(2**N)\n",
    "        for j in range(2**N)\n",
    "        for carry_in in range(2)\n",
    "    ]\n",
    "\n",
    "    inputs = [[int(x) for x in row] for row in inputs]\n",
    "\n",
    "    outputs = [ADDN(row[:N], row[N:2*N], row[2*N]) for row in inputs]\n",
    "\n",
    "    in_columns = [f\"a{i}\" for i in range(1, N+1)] + [f\"b{i}\" for i in range(1, N+1)] + [\"carry_in\"]\n",
    "    out_columns = [f\"sum{i}\" for i in range(1, N+1)] + [\"carry_out\"]\n",
    "\n",
    "    in_df = pd.DataFrame(inputs, columns=in_columns)\n",
    "    if add_constant:\n",
    "      in_df[\"Constant\"] = constant_value\n",
    "    out_df = pd.DataFrame(outputs, columns=out_columns)\n",
    "    return pd.concat([in_df, out_df], axis=1), len(in_df.columns), len(out_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2Ey6WH1tvf9"
   },
   "outputs": [],
   "source": [
    "class AdderDataset(Dataset):\n",
    "    def __init__(self, data, n_inputs):\n",
    "        self.data = data\n",
    "        self.n_inputs=n_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_data = torch.tensor(self.data.iloc[idx, :self.n_inputs].values, dtype=torch.float32)\n",
    "        target_data = torch.tensor(self.data.iloc[idx, self.n_inputs:].values, dtype=torch.float32)\n",
    "        return input_data, target_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrXZnbbJ_2Z8"
   },
   "source": [
    "# Noise Function\n",
    "Considering the noise as Guassian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-68DuWVfHfg"
   },
   "outputs": [],
   "source": [
    "def mul_guassian_noise(model,noise_percentage):\n",
    "  with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "      if param.requires_grad:\n",
    "        noise = torch.randn_like(param) * noise_percentage\n",
    "        param.mul_(1 + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75i8u644fIKl"
   },
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    #print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.to(device)\n",
    "    #print(f\"Model loaded from {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWaAepCU0-5f"
   },
   "source": [
    "## Quantized Linear function\n",
    "**round_to_nearest_values**: Approximate weights to predefined quantization levels for Quantization-Aware Training (QAT).\n",
    "\n",
    "---\n",
    "\n",
    "**QuantizedLinear**: A class that functions as a quantized fully connected (FC) layer when `PTQ` is `True`, and as a standard FC layer when `PTQ` is `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTclqolS1BD0"
   },
   "outputs": [],
   "source": [
    "rel_noise_percentage=0\n",
    "def add_noise(weights,relative_noise_percentage):\n",
    "  noise_standard_deviation =weights.abs().max() * relative_noise_percentage\n",
    "  noise = torch.randn_like(weights) * noise_standard_deviation\n",
    "  weights=weights+noise\n",
    "  return weights\n",
    "\n",
    "def round_to_nearest_values(tensor, values):\n",
    "    tensor.to(device)\n",
    "    values_tensor = torch.tensor(values, dtype=torch.float32).unsqueeze(0).to(device)  # Convert values list to tensor and add a batch dimension\n",
    "    diff = torch.abs(tensor.unsqueeze(-1) - values_tensor)  # Calculate absolute differences\n",
    "    min_indices = torch.argmin(diff, dim=-1)  # Find indices of minimum differences\n",
    "    return values_tensor[0, min_indices]  # Gather the nearest values\n",
    "\n",
    "class STEFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias=None, s=1.0):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        ctx.s = s\n",
    "\n",
    "        # Scale the weights\n",
    "        weight=add_noise(weight,rel_noise_percentage)\n",
    "        scaled_weight = weight / s\n",
    "\n",
    "        weight_q=round_to_nearest_values(scaled_weight, possible_weights)\n",
    "\n",
    "        if bias is not None:\n",
    "            # Apply similar logic to bias if necessary\n",
    "            scaled_bias = bias / s\n",
    "            bias_q = torch.sign(scaled_bias) * torch.where(torch.abs(scaled_bias) >= 1.5, 2,\n",
    "                                                           torch.where(torch.abs(scaled_bias) < 1.5, 1, 0))\n",
    "            output = F.linear(input, weight_q * s, bias_q * s)\n",
    "        else:\n",
    "            output = F.linear(input, weight_q * s)\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        s = ctx.s\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "            grad_weight = grad_weight / s\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0)\n",
    "            grad_bias = grad_bias / s\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias, None\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "# PTQ is a flag that if True simulates quantization with the possible weights and if False works as a standard FC layer\n",
    "class QuantizedLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=False, s=1.0, PTQ=False):\n",
    "        super(QuantizedLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.s = s\n",
    "        self.reset_parameters()\n",
    "        self.PTQ=PTQ\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.PTQ:\n",
    "          return STEFunction.apply(input, self.weight, self.bias, self.s)\n",
    "        else:\n",
    "          if self.bias is not None:\n",
    "             return F.linear(input,self.weight *self.s, self.bias*self.s)\n",
    "          else:\n",
    "            return F.linear(input, self.weight*self.s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRT_7wux1-IX"
   },
   "source": [
    "## Model\n",
    "**BinaryStep** activation and **MLP** model. The goal is to use a BinaryStep function with a threshold of 0.5 as the activation layer in this case. During the backward pass, we simulate a sigmoid function to facilitate better learning for the model. The MLP model has a parameter called `STEP` that determines the activation function used between layers. If `STEP` is `True`, the BinaryStep function is used as the activation function. If `STEP` is `False`, the sigmoid function is used as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wby1ZOkT1_ba"
   },
   "outputs": [],
   "source": [
    "class BinaryStep(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = torch.where(input >= 0.5, torch.tensor(1.), torch.tensor(0.))\n",
    "        ctx.save_for_backward(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "\n",
    "        # Calculate sigmoid derivative\n",
    "        sigmoid_derivative = torch.sigmoid(input) * (1 - torch.sigmoid(input))\n",
    "        grad_input *= sigmoid_derivative  # Element-wise multiplication with the sigmoid derivative\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_feat, num_classes, units, s=1.0, STEP=False):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        # Input layer\n",
    "        layers.append(QuantizedLinear(in_feat, units[0], s=s))\n",
    "        # Hidden layers\n",
    "        for i in range(1, len(units)):\n",
    "            layers.append(QuantizedLinear(units[i-1], units[i], s=s))\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(QuantizedLinear(units[-1], num_classes, s=s))\n",
    "\n",
    "        # Store layers as a ModuleList\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.act_qt = BinaryStep()\n",
    "        self.act_sig = nn.Sigmoid()\n",
    "        # If STEP is True, use BinaryStep activation layer with threshold on 0.5. If False, use sigmoid layer\n",
    "        self.STEP = STEP\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x)\n",
    "            x = self.act_qt.apply(x) if self.STEP else self.act_sig(x)\n",
    "\n",
    "        # Handle the last layer separately to apply sigmoid activation\n",
    "        x = self.layers[-1](x)\n",
    "        return self.act_qt.apply(x) if self.STEP else torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEi6Ag-U87iQ"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# Optional WarmupScheduler\n",
    "class WarmupScheduler(_LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_epochs, base_lr, final_lr, after_scheduler):\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.base_lr = base_lr\n",
    "        self.final_lr = final_lr\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished_warmup = False\n",
    "        super(WarmupScheduler, self).__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if not self.finished_warmup:\n",
    "            current_epoch = self.last_epoch + 1\n",
    "            if current_epoch <= self.warmup_epochs:\n",
    "                lr = self.base_lr + (self.final_lr - self.base_lr) * current_epoch / self.warmup_epochs\n",
    "                return [lr for _ in self.base_lrs]\n",
    "            else:\n",
    "                self.finished_warmup = True\n",
    "                self.after_scheduler.base_lrs = [self.final_lr for _ in self.base_lrs]\n",
    "        return self.after_scheduler.get_lr()\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if not self.finished_warmup:\n",
    "            super(WarmupScheduler, self).step(epoch)\n",
    "        else:\n",
    "            if epoch is not None:\n",
    "                self.after_scheduler.step(epoch - self.warmup_epochs)\n",
    "            else:\n",
    "                self.after_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ1hAbku5vHU"
   },
   "source": [
    "## Functions for training\n",
    "We use `clip_weights` after each epoch to ensure the weights remain close to the desired discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUkTcsOv5y_4"
   },
   "outputs": [],
   "source": [
    "def quantize_weights(model, s=1.0):\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            # Determine if we're dealing with weights or biases\n",
    "            if 'weight' in name or 'bias' in name:\n",
    "                # Scale the parameter\n",
    "                scaled_param = param / s\n",
    "                quantized_param =round_to_nearest_values(scaled_param, possible_weights)\n",
    "                # Scale back and update the parameter\n",
    "                param.copy_(quantized_param * s)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    # Convert probabilities to binary predictions\n",
    "    predicted = y_pred > 0.5\n",
    "    # Compare predictions to true values\n",
    "\n",
    "    correct = (predicted == y_true).float()  # Convert boolean to float for calculation\n",
    "    accuracy = correct.mean()  # Calculate mean accuracy per example\n",
    "    return accuracy\n",
    "\n",
    "def clip_weights(model, min_value, max_value):\n",
    "    for param in model.parameters():\n",
    "        param.data.clamp_(min_value, max_value)\n",
    "\n",
    "def evaluate_model(train_loader):\n",
    "    model.eval()\n",
    "    total_accuracy = 0\n",
    "    for x, y in train_loader:\n",
    "        print('x=', x)\n",
    "        print('y=', y)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        # print('output', output)\n",
    "        print('-----------')\n",
    "\n",
    "        total_accuracy += calculate_accuracy(y, output).item() / len(train_loader)\n",
    "\n",
    "    print(f'Model Accuracy: {total_accuracy*100}%')\n",
    "    return total_accuracy\n",
    "\n",
    "def get_weights(model):\n",
    "  w_dict={}\n",
    "  for name, param in model.named_parameters():\n",
    "      if param.requires_grad:\n",
    "          w_dict[name]=param.data.cpu().numpy().tolist()\n",
    "  return w_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urT6sDyxPyQT"
   },
   "source": [
    "# Main pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8wjA3G90Eyz"
   },
   "source": [
    "## Create dataset\n",
    "Simply define the number of bits **Nbits**, specify whether a constant column (**add_constant**) should be added, and provide the value for the constant column if needed (**constant_value**). The dataset will then be created automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bf666e1-506f-46c4-b5e5-c88f7ce9d651",
    "outputId": "e13e7f90-3bac-4722-9127-b1db93df2e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bits adder\n",
      "Batch_size: 8\n",
      "Data samples: 8\n"
     ]
    }
   ],
   "source": [
    "Nbits=1\n",
    "add_constant=True\n",
    "constant_value=-1\n",
    "\n",
    "###################################################################################################\n",
    "batch_size = 2**(2*Nbits+1) if Nbits<3 else int(2**(2*Nbits+1)/2)\n",
    "adderDf, n_inputs, n_outs = generate_adder_dataframe(N=Nbits, add_constant=add_constant, constant_value=constant_value)\n",
    "#################################################################################\n",
    "dataset = AdderDataset(adderDf, n_inputs)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(f\"{Nbits} bits adder\")\n",
    "print(f\"Batch_size: {batch_size}\")\n",
    "print(f'Data samples: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "ZZZJkUWE8lgd",
    "outputId": "031d4ba3-0f69-4f7c-ed7e-35ca9901057f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"adderDf\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"a1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carry_in\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Constant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": -1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carry_out\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "adderDf"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-aa33b1b3-c2a5-48d7-bc0e-fc96da645c9f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>b1</th>\n",
       "      <th>carry_in</th>\n",
       "      <th>Constant</th>\n",
       "      <th>sum1</th>\n",
       "      <th>carry_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa33b1b3-c2a5-48d7-bc0e-fc96da645c9f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-aa33b1b3-c2a5-48d7-bc0e-fc96da645c9f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-aa33b1b3-c2a5-48d7-bc0e-fc96da645c9f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-753869bc-19bd-4dca-8e0c-eb833b5c3934\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-753869bc-19bd-4dca-8e0c-eb833b5c3934')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-753869bc-19bd-4dca-8e0c-eb833b5c3934 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   a1  b1  carry_in  Constant  sum1  carry_out\n",
       "0   0   0         0        -1     0          0\n",
       "1   0   0         1        -1     1          0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adderDf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q6uRJQ657TK"
   },
   "source": [
    "## Create model\n",
    "Simply modify the `possible_weights` and `units` parameters. The model will then be created automatically and printed below.\n",
    "\n",
    "- **possible_weights**: A list of possible weight values to be used in the model.\n",
    "- **units**: A list where the size represents the number of layers, and each value indicates the number of units in each corresponding layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibo8KraRYMqg",
    "outputId": "c00bb59f-d1d4-4799-a4d3-28cb22d95fca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-137-e02185d1a7a8>:37: DeprecationWarning: <class '__main__.BinaryStep'> should not be instantiated. Methods on autograd functionsare all static, so you should invoke them on the class itself. Instantiating an autograd function will raise an error in a future version of PyTorch.\n",
      "  self.act_qt = BinaryStep()\n"
     ]
    }
   ],
   "source": [
    "possible_weights=[-4,-2,0,2,4] # Weights to use in the model\n",
    "units=[5] # The number of elements in units list represent th number of hidden layers and the value the units of each layer. [5,5] means two hidden layers of 5 units each.\n",
    "weights_path='/content/drive/MyDrive/one_bit_weights.pth'# If you want to load some pretrained weights\n",
    "model = MLP(in_feat=n_inputs, num_classes=n_outs,units=units, s=1.0, STEP=False).to(device) # Initialize with STEP== False. It means without step function as activation\n",
    "load_model(model,weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMHi-aow3k57",
    "outputId": "255242fb-644b-44c0-c07a-02ce607f8869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   QuantizedLinear-1                 [-1, 1, 5]              20\n",
      "           Sigmoid-2                 [-1, 1, 5]               0\n",
      "   QuantizedLinear-3                 [-1, 1, 2]              10\n",
      "================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1, n_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E3wvCGGm3rRY",
    "outputId": "1c42f314-b027-4ec9-e4fb-6c945a64895a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0],\n",
       "  [-2.0, 4.0, -2.0, -4.0],\n",
       "  [-4.0, -4.0, -4.0, 0.0],\n",
       "  [4.0, 4.0, 4.0, 4.0],\n",
       "  [-4.0, 4.0, -4.0, -2.0]],\n",
       " 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0],\n",
       "  [-2.0, 0.0, -2.0, 2.0, 0.0]]}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cR0UYtts9ptb",
    "outputId": "5edb9133-34bc-49fe-d2a5-48abbbb19948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start LR: 0.01\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "max_epochs=20000 # Default\n",
    "T_max=10000 # Epochs for cosine_scheduler\n",
    "warmup_epochs=2000 # 0 if no warmup. I used 2000 and it worked fine.\n",
    "base_lr=0.0 # initial learning rate\n",
    "\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "cosine_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "warmup_scheduler = WarmupScheduler(\n",
    "    optimizer,\n",
    "    warmup_epochs=warmup_epochs,\n",
    "    base_lr=0.0,  # Starting from 0\n",
    "    final_lr=lr,  # Target learning rate after warmup\n",
    "    after_scheduler=cosine_scheduler\n",
    ")\n",
    "\n",
    "print(f\"Start LR: {lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcOf1RDSw7la"
   },
   "source": [
    "# Noise Injection Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJpOMUVFw6VH",
    "outputId": "7d023789-2eb5-4ec4-a301-61d305dd263a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Noise Percentage 0.0, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.01, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 1.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.]])\n",
      "y= tensor([[1., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.02, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:855: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Noise Percentage 0.03, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.04, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.05, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.06, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.07, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  0., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.08, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 0.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.09, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  0., -1.]])\n",
      "y= tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.1, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  0.,  0., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.]])\n",
      "y= tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.11, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.]])\n",
      "y= tensor([[0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.12, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 1.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  1.,  0., -1.]])\n",
      "y= tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 0.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.13, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  1.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  1., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 93.75%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.14, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  0.,  1., -1.]])\n",
      "y= tensor([[0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.15, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  0.,  1., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 68.75%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.16, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 87.5%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.17, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  1.,  0., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 75.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.18, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.]])\n",
      "y= tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 68.75%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.19, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  1., -1.]])\n",
      "y= tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 0.]])\n",
      "-----------\n",
      "Model Accuracy: 100.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.2, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 0.,  1.,  0., -1.],\n",
      "        [ 1.,  0.,  0., -1.]])\n",
      "y= tensor([[0., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "-----------\n",
      "Model Accuracy: 75.0%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n",
      "------------ Noise Percentage 0.21, Accuracy: 1.0000------------- \n",
      "x= tensor([[ 0.,  1.,  0., -1.],\n",
      "        [ 0.,  0.,  1., -1.],\n",
      "        [ 1.,  0.,  0., -1.],\n",
      "        [ 0.,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  0., -1.],\n",
      "        [ 1.,  0.,  1., -1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 1.,  1.,  1., -1.]])\n",
      "y= tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 1.]])\n",
      "-----------\n",
      "Model Accuracy: 81.25%\n",
      "{'layers.0.weight': [[-4.0, -4.0, -4.0, -2.0], [-2.0, 4.0, -2.0, -4.0], [-4.0, -4.0, -4.0, 0.0], [4.0, 4.0, 4.0, 4.0], [-4.0, 4.0, -4.0, -2.0]], 'layers.1.weight': [[-4.0, 4.0, -4.0, -2.0, -2.0], [-2.0, 0.0, -2.0, 2.0, 0.0]]}\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,31):\n",
    "  rel_noise_percentage=i/100\n",
    "  now = datetime.now()\n",
    "  start_time = now.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "  best_accuracy=0\n",
    "  for epoch in range(max_epochs):\n",
    "    for layer in model.layers:\n",
    "      layer.PTQ=True\n",
    "    model.STEP=True\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        total_accuracy += calculate_accuracy(y, output).item()\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        clip_weights(model, min(possible_weights)-1, max(possible_weights)+1)\n",
    "        total_loss += loss.item()\n",
    "    warmup_scheduler.step()\n",
    "    if (epoch+1) % 500 == 0:\n",
    "      average_loss = total_loss / len(train_loader)\n",
    "      average_accuracy = total_accuracy / len(train_loader)\n",
    "      if average_accuracy ==1.0:\n",
    "        print(f'------------ Noise Percentage {rel_noise_percentage}, Accuracy: {average_accuracy:.4f}------------- ')\n",
    "        quantize_weights(model)\n",
    "        evaluate_model(train_loader)\n",
    "        save_model(model, f'/content/drive/MyDrive/one_bit_NAT_{rel_noise_percentage}.pt')\n",
    "        load_model(model,f'/content/drive/MyDrive/one_bit_weights.pth')\n",
    "        print(get_weights(model))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nliiQXxJpY_s"
   },
   "source": [
    "# Accuracy Measurements with different Noise factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c50tIY9BLehb"
   },
   "outputs": [],
   "source": [
    "def new_evaluate_model(model,train_loader):\n",
    "    model.eval()\n",
    "    total_accuracy = 0\n",
    "    for x, y in train_loader:\n",
    "        #print('x=', x)\n",
    "        #print('y=', y)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        # print('output', output)\n",
    "        #print('-----------')\n",
    "\n",
    "        total_accuracy += calculate_accuracy(y, output).item() / len(train_loader)\n",
    "\n",
    "    #print(f'Model Accuracy: {total_accuracy*100}%')\n",
    "    return total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "58o3oVjhpXxX",
    "outputId": "216a2f87-65cd-423e-bb80-16f0a1d03e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rel_noise_percentage=0\n",
    "test_results=list()\n",
    "for i in range(0,31):\n",
    "  model_copy = model\n",
    "  load_model(model_copy,f'/content/drive/MyDrive/one_bit_NAT_{i/100}.pt')\n",
    "  test_results.append(new_evaluate_model(model_copy,train_loader)*100)\n",
    "print(test_results)\n",
    "plt.title('One bit accuracy measurements (AGN)')\n",
    "plt.plot(test_results,)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Noise Percentage')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
