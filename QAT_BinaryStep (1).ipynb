{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, functions and classes"
      ],
      "metadata": {
        "id": "ipgaw8VwPfAE"
      },
      "id": "ipgaw8VwPfAE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "GkXRKd8HrFcG"
      },
      "id": "GkXRKd8HrFcG"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a3123909-6f2a-41b9-8545-28d6290350d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a3123909-6f2a-41b9-8545-28d6290350d7",
        "outputId": "6fef5963-8e01-4e3e-cb0c-bb982246caa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import json\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import itertools\n",
        "import pandas as pd\n",
        "!pip install -q torchsummary\n",
        "from torchsummary import summary\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adder dataloader\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "General adder to define dataloader automatically based on Nbits"
      ],
      "metadata": {
        "id": "6j4KlWvvrepV"
      },
      "id": "6j4KlWvvrepV"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def NAND(x, y):\n",
        "     if x == 0 and y == 0: return 1\n",
        "     if x == 0 and y == 1: return 1\n",
        "     if x == 1 and y == 0: return 1\n",
        "     if x == 1 and y == 1: return 0\n",
        "\n",
        "def NOT(x):\n",
        "     return NAND(x, x)\n",
        "\n",
        "def AND(x, y):\n",
        "     return NOT(NAND(x, y))\n",
        "\n",
        "def OR(x, y):\n",
        "     return NAND(NAND(x, x), NAND(y, y))\n",
        "\n",
        "def XOR(x, y):\n",
        "     return AND(OR(x, y),\n",
        "                NOT(AND(x, y)))\n",
        "\n",
        "def HALF(x, y):\n",
        "     carry = AND(x, y)\n",
        "     sum = XOR(x, y)\n",
        "     return (carry, sum)\n",
        "\n",
        "def FULL(x, y, carry_in):\n",
        "     carry1, sum1 = HALF(x, y)\n",
        "     carry2, sum2 = HALF(carry_in, sum1)\n",
        "     carry_out = OR(carry1, carry2)\n",
        "     return (carry_out, sum2)\n",
        "\n",
        "def ADDN(left, right, carry_in):\n",
        "    N = len(left)\n",
        "    sums = []\n",
        "    carry = carry_in\n",
        "\n",
        "    for i in range(N-1, -1, -1):\n",
        "        carry, sum_ = FULL(left[i], right[i], carry)\n",
        "        sums.insert(0, sum_)\n",
        "\n",
        "    return sums + [carry]\n",
        "\n",
        "\n",
        "def generate_adder_dataframe(N, add_constant=True, constant_value=1):\n",
        "    inputs = [\n",
        "        [*bin(i)[2:].zfill(N), *bin(j)[2:].zfill(N), carry_in]\n",
        "        for i in range(2**N)\n",
        "        for j in range(2**N)\n",
        "        for carry_in in range(2)\n",
        "    ]\n",
        "\n",
        "    inputs = [[int(x) for x in row] for row in inputs]\n",
        "\n",
        "    outputs = [ADDN(row[:N], row[N:2*N], row[2*N]) for row in inputs]\n",
        "\n",
        "    in_columns = [f\"a{i}\" for i in range(1, N+1)] + [f\"b{i}\" for i in range(1, N+1)] + [\"carry_in\"]\n",
        "    out_columns = [f\"sum{i}\" for i in range(1, N+1)] + [\"carry_out\"]\n",
        "\n",
        "    in_df = pd.DataFrame(inputs, columns=in_columns)\n",
        "    if add_constant:\n",
        "      in_df[\"Constant\"] = constant_value\n",
        "    out_df = pd.DataFrame(outputs, columns=out_columns)\n",
        "    return pd.concat([in_df, out_df], axis=1), len(in_df.columns), len(out_df.columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "3582GaEMtd5d"
      },
      "id": "3582GaEMtd5d",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdderDataset(Dataset):\n",
        "    def __init__(self, data, n_inputs):\n",
        "        self.data = data\n",
        "        self.n_inputs=n_inputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data = torch.tensor(self.data.iloc[idx, :self.n_inputs].values, dtype=torch.float32)\n",
        "        target_data = torch.tensor(self.data.iloc[idx, self.n_inputs:].values, dtype=torch.float32)\n",
        "        return input_data, target_data\n",
        "\n"
      ],
      "metadata": {
        "id": "E2Ey6WH1tvf9"
      },
      "id": "E2Ey6WH1tvf9",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantized Linear function\n",
        "**round_to_nearest_values**: Approximate weights to predefined quantization levels for Quantization-Aware Training (QAT).\n",
        "\n",
        "---\n",
        "\n",
        "**QuantizedLinear**: A class that functions as a quantized fully connected (FC) layer when `PTQ` is `True`, and as a standard FC layer when `PTQ` is `False`.\n"
      ],
      "metadata": {
        "id": "qWaAepCU0-5f"
      },
      "id": "qWaAepCU0-5f"
    },
    {
      "cell_type": "code",
      "source": [
        "def round_to_nearest_values(tensor, values):\n",
        "    tensor.to(device)\n",
        "    values_tensor = torch.tensor(values, dtype=torch.float32).unsqueeze(0).to(device)  # Convert values list to tensor and add a batch dimension\n",
        "    diff = torch.abs(tensor.unsqueeze(-1) - values_tensor)  # Calculate absolute differences\n",
        "    min_indices = torch.argmin(diff, dim=-1)  # Find indices of minimum differences\n",
        "    return values_tensor[0, min_indices]  # Gather the nearest values\n",
        "\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weight, bias=None, s=1.0):\n",
        "        ctx.save_for_backward(input, weight, bias)\n",
        "        ctx.s = s\n",
        "\n",
        "        # Scale the weights\n",
        "        scaled_weight = weight / s\n",
        "\n",
        "        weight_q=round_to_nearest_values(scaled_weight, possible_weights)\n",
        "        if bias is not None:\n",
        "            # Apply similar logic to bias if necessary\n",
        "            scaled_bias = bias / s\n",
        "            bias_q = torch.sign(scaled_bias) * torch.where(torch.abs(scaled_bias) >= 1.5, 2,\n",
        "                                                           torch.where(torch.abs(scaled_bias) < 1.5, 1, 0))\n",
        "            output = F.linear(input, weight_q * s, bias_q * s)\n",
        "        else:\n",
        "            output = F.linear(input, weight_q * s)\n",
        "\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, weight, bias = ctx.saved_tensors\n",
        "        s = ctx.s\n",
        "        grad_input = grad_weight = grad_bias = None\n",
        "\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            grad_input = grad_output.mm(weight)\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            grad_weight = grad_output.t().mm(input)\n",
        "            grad_weight = grad_weight / s\n",
        "        if bias is not None and ctx.needs_input_grad[2]:\n",
        "            grad_bias = grad_output.sum(0)\n",
        "            grad_bias = grad_bias / s\n",
        "\n",
        "        return grad_input, grad_weight, grad_bias, None\n",
        "###########################################################################################################\n",
        "# PTQ is a flag that if True simulates quantization with the possible weights and if False works as a standard FC layer\n",
        "class QuantizedLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=False, s=1.0, PTQ=False):\n",
        "        super(QuantizedLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.s = s\n",
        "        self.reset_parameters()\n",
        "        self.PTQ=PTQ\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            nn.init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input):\n",
        "        if self.PTQ:\n",
        "          return STEFunction.apply(input, self.weight, self.bias, self.s)\n",
        "        else:\n",
        "          if self.bias is not None:\n",
        "             return F.linear(input,self.weight *self.s, self.bias*self.s)\n",
        "          else:\n",
        "            return F.linear(input, self.weight*self.s)\n"
      ],
      "metadata": {
        "id": "XTclqolS1BD0"
      },
      "id": "XTclqolS1BD0",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "**BinaryStep** activation and **MLP** model. The goal is to use a BinaryStep function with a threshold of 0.5 as the activation layer in this case. During the backward pass, we simulate a sigmoid function to facilitate better learning for the model. The MLP model has a parameter called `STEP` that determines the activation function used between layers. If `STEP` is `True`, the BinaryStep function is used as the activation function. If `STEP` is `False`, the sigmoid function is used as the activation function."
      ],
      "metadata": {
        "id": "eRT_7wux1-IX"
      },
      "id": "eRT_7wux1-IX"
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryStep(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        output = torch.where(input >= 0.5, torch.tensor(1.), torch.tensor(0.))\n",
        "        ctx.save_for_backward(input)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "\n",
        "        # Calculate sigmoid derivative\n",
        "        sigmoid_derivative = torch.sigmoid(input) * (1 - torch.sigmoid(input))\n",
        "        grad_input *= sigmoid_derivative  # Element-wise multiplication with the sigmoid derivative\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_feat, num_classes, units, s=1.0, STEP=False):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        # Input layer\n",
        "        layers.append(QuantizedLinear(in_feat, units[0], s=s))\n",
        "        # Hidden layers\n",
        "        for i in range(1, len(units)):\n",
        "            layers.append(QuantizedLinear(units[i-1], units[i], s=s))\n",
        "\n",
        "        # Output layer\n",
        "        layers.append(QuantizedLinear(units[-1], num_classes, s=s))\n",
        "\n",
        "        # Store layers as a ModuleList\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "        self.act_qt = BinaryStep()\n",
        "        self.act_sig = nn.Sigmoid()\n",
        "        # If STEP is True, use BinaryStep activation layer with threshold on 0.5. If False, use sigmoid layer\n",
        "        self.STEP = STEP\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = layer(x)\n",
        "            x = self.act_qt.apply(x) if self.STEP else self.act_sig(x)\n",
        "\n",
        "        # Handle the last layer separately to apply sigmoid activation\n",
        "        x = self.layers[-1](x)\n",
        "        return self.act_qt.apply(x) if self.STEP else torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "Wby1ZOkT1_ba"
      },
      "id": "Wby1ZOkT1_ba",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "# Optional WarmupScheduler\n",
        "class WarmupScheduler(_LRScheduler):\n",
        "    def __init__(self, optimizer, warmup_epochs, base_lr, final_lr, after_scheduler):\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.base_lr = base_lr\n",
        "        self.final_lr = final_lr\n",
        "        self.after_scheduler = after_scheduler\n",
        "        self.finished_warmup = False\n",
        "        super(WarmupScheduler, self).__init__(optimizer)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if not self.finished_warmup:\n",
        "            current_epoch = self.last_epoch + 1\n",
        "            if current_epoch <= self.warmup_epochs:\n",
        "                lr = self.base_lr + (self.final_lr - self.base_lr) * current_epoch / self.warmup_epochs\n",
        "                return [lr for _ in self.base_lrs]\n",
        "            else:\n",
        "                self.finished_warmup = True\n",
        "                self.after_scheduler.base_lrs = [self.final_lr for _ in self.base_lrs]\n",
        "        return self.after_scheduler.get_lr()\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if not self.finished_warmup:\n",
        "            super(WarmupScheduler, self).step(epoch)\n",
        "        else:\n",
        "            if epoch is not None:\n",
        "                self.after_scheduler.step(epoch - self.warmup_epochs)\n",
        "            else:\n",
        "                self.after_scheduler.step()\n"
      ],
      "metadata": {
        "id": "SEi6Ag-U87iQ"
      },
      "id": "SEi6Ag-U87iQ",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for training\n",
        "We use `clip_weights` after each epoch to ensure the weights remain close to the desired discrete values."
      ],
      "metadata": {
        "id": "UQ1hAbku5vHU"
      },
      "id": "UQ1hAbku5vHU"
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_weights(model, s=1.0):\n",
        "    with torch.no_grad():\n",
        "        for name, param in model.named_parameters():\n",
        "            # Determine if we're dealing with weights or biases\n",
        "            if 'weight' in name or 'bias' in name:\n",
        "                # Scale the parameter\n",
        "                scaled_param = param / s\n",
        "                quantized_param =round_to_nearest_values(scaled_param, possible_weights)\n",
        "                # Scale back and update the parameter\n",
        "                param.copy_(quantized_param * s)\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    # Convert probabilities to binary predictions\n",
        "    predicted = y_pred > 0.5\n",
        "    # Compare predictions to true values\n",
        "\n",
        "    correct = (predicted == y_true).float()  # Convert boolean to float for calculation\n",
        "    accuracy = correct.mean()  # Calculate mean accuracy per example\n",
        "    return accuracy\n",
        "\n",
        "def clip_weights(model, min_value, max_value):\n",
        "    for param in model.parameters():\n",
        "        param.data.clamp_(min_value, max_value)\n",
        "\n",
        "def evaluate_model(train_loader):\n",
        "    model.eval()\n",
        "    total_accuracy = 0\n",
        "    for x, y in train_loader:\n",
        "        print('x=', x)\n",
        "        print('y=', y)\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        # print('output', output)\n",
        "        print('-----------')\n",
        "\n",
        "        total_accuracy += calculate_accuracy(y, output).item() / len(train_loader)\n",
        "\n",
        "    print(f'Model Accuracy: {total_accuracy*100}%')\n",
        "    return total_accuracy\n",
        "\n",
        "def get_weights(model):\n",
        "  w_dict={}\n",
        "  for name, param in model.named_parameters():\n",
        "      if param.requires_grad:\n",
        "          w_dict[name]=param.data.cpu().numpy().tolist()\n",
        "  return w_dict"
      ],
      "metadata": {
        "id": "WUkTcsOv5y_4"
      },
      "id": "WUkTcsOv5y_4",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main pipeline"
      ],
      "metadata": {
        "id": "urT6sDyxPyQT"
      },
      "id": "urT6sDyxPyQT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dataset\n",
        "Simply define the number of bits **Nbits**, specify whether a constant column (**add_constant**) should be added, and provide the value for the constant column if needed (**constant_value**). The dataset will then be created automatically."
      ],
      "metadata": {
        "id": "Y8wjA3G90Eyz"
      },
      "id": "Y8wjA3G90Eyz"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "2bf666e1-506f-46c4-b5e5-c88f7ce9d651",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2bf666e1-506f-46c4-b5e5-c88f7ce9d651",
        "outputId": "c72185e5-c884-4a20-d079-6377dfb45c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 bits adder\n",
            "Batch_size: 8\n",
            "Data samples: 8\n"
          ]
        }
      ],
      "source": [
        "Nbits=1\n",
        "add_constant=True\n",
        "constant_value=-1\n",
        "\n",
        "###################################################################################################\n",
        "batch_size = 2**(2*Nbits+1) if Nbits<3 else int(2**(2*Nbits+1)/2)\n",
        "adderDf, n_inputs, n_outs = generate_adder_dataframe(N=Nbits, add_constant=add_constant, constant_value=constant_value)\n",
        "#################################################################################\n",
        "dataset = AdderDataset(adderDf, n_inputs)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "print(f\"{Nbits} bits adder\")\n",
        "print(f\"Batch_size: {batch_size}\")\n",
        "print(f'Data samples: {len(dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adderDf.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "ZZZJkUWE8lgd",
        "outputId": "43367c25-645b-427d-e8fe-4ef5e3c6e2c4"
      },
      "id": "ZZZJkUWE8lgd",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   a1  b1  carry_in  Constant  sum1  carry_out\n",
              "0   0   0         0        -1     0          0\n",
              "1   0   0         1        -1     1          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb2e8e57-68e2-4ed5-a4cd-131d0ffaaac1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a1</th>\n",
              "      <th>b1</th>\n",
              "      <th>carry_in</th>\n",
              "      <th>Constant</th>\n",
              "      <th>sum1</th>\n",
              "      <th>carry_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb2e8e57-68e2-4ed5-a4cd-131d0ffaaac1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb2e8e57-68e2-4ed5-a4cd-131d0ffaaac1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb2e8e57-68e2-4ed5-a4cd-131d0ffaaac1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f2c566d0-e0b5-4c34-9670-682e06d0dab2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2c566d0-e0b5-4c34-9670-682e06d0dab2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f2c566d0-e0b5-4c34-9670-682e06d0dab2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "adderDf",
              "summary": "{\n  \"name\": \"adderDf\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"a1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carry_in\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Constant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": -1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carry_out\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model\n",
        "Simply modify the `possible_weights` and `units` parameters. The model will then be created automatically and printed below.\n",
        "\n",
        "- **possible_weights**: A list of possible weight values to be used in the model.\n",
        "- **units**: A list where the size represents the number of layers, and each value indicates the number of units in each corresponding layer.\n"
      ],
      "metadata": {
        "id": "3Q6uRJQ657TK"
      },
      "id": "3Q6uRJQ657TK"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "ibo8KraRYMqg",
      "metadata": {
        "id": "ibo8KraRYMqg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "788999c3-de23-4dde-90e1-ac84348bf727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "   QuantizedLinear-1                    [-1, 5]              20\n",
            "           Sigmoid-2                    [-1, 5]               0\n",
            "   QuantizedLinear-3                    [-1, 2]              10\n",
            "================================================================\n",
            "Total params: 30\n",
            "Trainable params: 30\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-3c02ab4e8969>:37: DeprecationWarning: <class '__main__.BinaryStep'> should not be instantiated. Methods on autograd functionsare all static, so you should invoke them on the class itself. Instantiating an autograd function will raise an error in a future version of PyTorch.\n",
            "  self.act_qt = BinaryStep()\n"
          ]
        }
      ],
      "source": [
        "possible_weights=[-4,-2,0,2,4] # Weights to use in the model\n",
        "units=[5] # The number of elements in units list represent th number of hidden layers and the value the units of each layer. [5,5] means two hidden layers of 5 units each.\n",
        "weights_path=None # If you want to load some pretrained weights\n",
        "\n",
        "\n",
        "################################################################################\n",
        "model = MLP(in_feat=n_inputs, num_classes=n_outs,units=units, s=1.0, STEP=False).to(device) # Initialize with STEP== False. It means without step function as activation\n",
        "if weights_path is not None:\n",
        "  model.load_state_dict(torch.load(weights_path))\n",
        "summary(model, (tuple([n_inputs])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training parameters\n",
        "\n",
        "The primary goal is to train the model using Quantization Aware Training (QAT) across multiple stages.\n",
        "\n",
        "- **Stage 0**: The weights are quantized, and the layers use the Sigmoid activation function for two epochs, followed by the BinaryStep activation function for one epoch. This alternation helps ease the training process and guide the model towards a weight distribution close to the desired values, aiming for 100% accuracy.\n",
        "- **Stage 1**: The model alternates between Sigmoid and BinaryStep activations every epoch until it achieves 100% accuracy.\n",
        "- **Stage 2**: The BinaryStep activation is used more frequently than Sigmoid.\n",
        "- **Stage 3**: Only BinaryStep activation is used.\n",
        "\n",
        "We also use a cosine scheduler and clip the weights after each epoch to facilitate convergence. If the model does not converge, you may need to increase the number of units or adjust the learning rate.\n",
        "\n",
        "The weights of the best-performing model are saved automatically. If the training gets stuck at any stage, you can stop the process, load the best weights so far, modify the initial stage, and reduce the learning rate to prevent the weights from being destabilized.\n"
      ],
      "metadata": {
        "id": "sTv_J5ec9qgI"
      },
      "id": "sTv_J5ec9qgI"
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.01 # Default\n",
        "stage=0\n",
        "max_epochs=200000 # Default\n",
        "T_max=10000 # Epochs for cosine_scheduler\n",
        "warmup_epochs=2000 # 0 if no warmup. I used 2000 and it worked fine.\n",
        "base_lr=0.0 # initial learning rate\n",
        "\n",
        "##################################################################################\n",
        "##################################################################################\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "cosine_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
        "warmup_scheduler = WarmupScheduler(\n",
        "    optimizer,\n",
        "    warmup_epochs=warmup_epochs,\n",
        "    base_lr=0.0,  # Starting from 0\n",
        "    final_lr=lr,  # Target learning rate after warmup\n",
        "    after_scheduler=cosine_scheduler\n",
        ")\n",
        "\n",
        "print(f\"Start LR: {lr}\")\n",
        "print(f\"Start in stage {stage}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cR0UYtts9ptb",
        "outputId": "2ec3bf4c-b3a8-4d60-a6a0-6993b3783836"
      },
      "id": "cR0UYtts9ptb",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start LR: 0.01\n",
            "Start in stage 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "\n",
        "After the model finishes training, a JSON file is automatically saved with the date of the training as its name. This file contains essential information about the dataset, hyperparameters, and the size of the model. Additionally, it includes the quantized weights and the achieved accuracy."
      ],
      "metadata": {
        "id": "HEBZOUN5Gp3p"
      },
      "id": "HEBZOUN5Gp3p"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "dd0f97b7-b653-4525-9d20-881c7c8f4023",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dd0f97b7-b653-4525-9d20-881c7c8f4023",
        "scrolled": true,
        "outputId": "3516baf1-2e07-444b-ae84-eda89d8999e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "0.625\n",
            "Epoch 500, Loss: 50.0000, Accuracy: 0.5000\n",
            "Epoch 1000, Loss: 50.0000, Accuracy: 0.5000\n",
            "0.6875\n",
            "Epoch 1500, Loss: 37.5000, Accuracy: 0.6250\n",
            "0.75\n",
            "0.8125\n",
            "0.9375\n",
            "Epoch 2000, Loss: 6.2500, Accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:855: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2500, Loss: 50.0000, Accuracy: 0.5000\n",
            "Epoch 3000, Loss: 37.5000, Accuracy: 0.6250\n",
            "Epoch 3500, Loss: 25.0000, Accuracy: 0.7500\n",
            "Epoch 4000, Loss: 25.0000, Accuracy: 0.7500\n",
            "Epoch 4500, Loss: 18.7500, Accuracy: 0.8125\n",
            "Epoch 5000, Loss: 18.7500, Accuracy: 0.8125\n",
            "Epoch 5500, Loss: 25.0000, Accuracy: 0.7500\n",
            "Epoch 6000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 6500, Loss: 18.7500, Accuracy: 0.8125\n",
            "Epoch 7000, Loss: 43.7500, Accuracy: 0.5625\n",
            "Epoch 7500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 8000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 8500, Loss: 37.5000, Accuracy: 0.6250\n",
            "Epoch 9000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 9500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 10000, Loss: 18.7500, Accuracy: 0.8125\n",
            "Epoch 10500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 11000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 11500, Loss: 18.7500, Accuracy: 0.8125\n",
            "Epoch 12000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 12500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 13000, Loss: 37.5000, Accuracy: 0.6250\n",
            "Epoch 13500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 14000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 14500, Loss: 31.2500, Accuracy: 0.6875\n",
            "Epoch 15000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 15500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 16000, Loss: 25.0000, Accuracy: 0.7500\n",
            "Epoch 16500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 17000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 17500, Loss: 25.0000, Accuracy: 0.7500\n",
            "Epoch 18000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 18500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 19000, Loss: 18.7500, Accuracy: 0.8125\n",
            "Epoch 19500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 20000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 20500, Loss: 18.7500, Accuracy: 0.8125\n",
            "Epoch 21000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 21500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 22000, Loss: 25.0000, Accuracy: 0.7500\n",
            "Epoch 22500, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 23000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 23500, Loss: 18.7500, Accuracy: 0.8125\n",
            "Epoch 24000, Loss: 6.2500, Accuracy: 0.9375\n",
            "Epoch 24500, Loss: 12.5000, Accuracy: 0.8750\n",
            "Epoch 25000, Loss: 6.2500, Accuracy: 0.9375\n",
            "1.0\n",
            "stage:  1\n",
            "0.8125\n",
            "1.0\n",
            "stage:  2\n",
            "0.875\n",
            "1.0\n",
            "stage:  3\n",
            "0.875\n",
            "0.9375\n",
            "1.0\n",
            "stage:  4\n",
            "x= tensor([[ 0.,  0.,  1., -1.],\n",
            "        [ 0.,  0.,  0., -1.],\n",
            "        [ 0.,  1.,  0., -1.],\n",
            "        [ 1.,  1.,  1., -1.],\n",
            "        [ 1.,  0.,  1., -1.],\n",
            "        [ 1.,  1.,  0., -1.],\n",
            "        [ 1.,  0.,  0., -1.],\n",
            "        [ 0.,  1.,  1., -1.]])\n",
            "y= tensor([[1., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]])\n",
            "-----------\n",
            "Model Accuracy: 100.0%\n"
          ]
        }
      ],
      "source": [
        "now = datetime.now()\n",
        "start_time = now.strftime(\"%Y_%m_%d_%H_%M\")\n",
        "\n",
        "best_accuracy=0\n",
        "for epoch in range(max_epochs):  # Number of epochs\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    if stage==0:\n",
        "      if epoch%3==0:\n",
        "        for layer in model.layers:\n",
        "          layer.PTQ=True\n",
        "        model.STEP=True\n",
        "      else:\n",
        "        for layer in model.layers:\n",
        "          layer.PTQ=False\n",
        "        model.STEP=True\n",
        "    if stage==1:\n",
        "      if epoch%2==0:\n",
        "        for layer in model.layers:\n",
        "          layer.PTQ=True\n",
        "        model.STEP=True\n",
        "      else:\n",
        "        for layer in model.layers:\n",
        "          layer.PTQ=False\n",
        "        model.STEP=True\n",
        "    if stage==2:\n",
        "      if epoch%5==0:\n",
        "        for layer in model.layers:\n",
        "          layer.PTQ=False\n",
        "        model.STEP=True\n",
        "      else:\n",
        "        for layer in model.layers:\n",
        "          layer.PTQ=True\n",
        "        model.STEP=True\n",
        "    if stage==3:\n",
        "        for layer in model.layers:\n",
        "          layer.PTQ=True\n",
        "        model.STEP=True\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        total_accuracy += calculate_accuracy(y, output).item()\n",
        "\n",
        "        if (total_accuracy/len(train_loader))>best_accuracy:\n",
        "          best_accuracy=(total_accuracy/len(train_loader))\n",
        "          print(best_accuracy)\n",
        "          torch.save(model.state_dict(), f'{Nbits}bits_best_model_{start_time}.pth')\n",
        "        if (total_accuracy / len(train_loader) == 1.0 and stage==3) or (total_accuracy / len(train_loader) == 1.0 and stage<3):\n",
        "          print(\"stage: \",stage+1)\n",
        "          torch.save(model.state_dict(), f'{Nbits}bits_stage_model_{start_time}.pth')\n",
        "          best_accuracy=0\n",
        "          stage=stage+1\n",
        "          break\n",
        "\n",
        "        loss = loss_function(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        clip_weights(model, min(possible_weights)-1, max(possible_weights)+1)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    warmup_scheduler.step()\n",
        "    if total_accuracy / len(train_loader) == 1 and stage==4:\n",
        "          break\n",
        "    if (epoch+1) % 500 == 0:\n",
        "        average_loss = total_loss / len(train_loader)\n",
        "        average_accuracy = total_accuracy / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {average_loss:.4f}, Accuracy: {average_accuracy:.4f}')\n",
        "\n",
        "\n",
        "quantize_weights(model)\n",
        "\n",
        "#### Save model results #################################################\n",
        "model_dict={\n",
        "    \"Nbits\":Nbits,\n",
        "    \"Batch_size\":batch_size,\n",
        "    \"Add_constant\":add_constant,\n",
        "    \"Constant_value\":constant_value if add_constant else None,\n",
        "    \"n_inputs\":n_inputs,\n",
        "    \"n_outputs\":n_outs,\n",
        "    \"possible_weights\": possible_weights, # Weights to use in the model\n",
        "    \"units\":units,\n",
        "    \"total_accuracy\": evaluate_model(train_loader),\n",
        "    \"quantized_weights\": get_weights(model)\n",
        "}\n",
        "\n",
        "with open(f'{Nbits}bits_training_{start_time}.json', 'w') as json_file:\n",
        "    json.dump(model_dict, json_file, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "0SprmVRnGy8Y"
      },
      "id": "0SprmVRnGy8Y"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "550d9bc7-0d8e-4af7-ae93-980007fc83a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "550d9bc7-0d8e-4af7-ae93-980007fc83a7",
        "outputId": "125c0ac9-0796-47ca-83c9-0f1fba87d25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= tensor([[ 1.,  1.,  0., -1.],\n",
            "        [ 0.,  0.,  1., -1.],\n",
            "        [ 1.,  0.,  1., -1.],\n",
            "        [ 1.,  1.,  1., -1.],\n",
            "        [ 0.,  1.,  1., -1.],\n",
            "        [ 0.,  0.,  0., -1.],\n",
            "        [ 0.,  1.,  0., -1.],\n",
            "        [ 1.,  0.,  0., -1.]])\n",
            "y= tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]])\n",
            "-----------\n",
            "Model Accuracy: 100.0%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "evaluate_model(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check quantized parameters"
      ],
      "metadata": {
        "id": "pAL42CE0G6NV"
      },
      "id": "pAL42CE0G6NV"
    },
    {
      "cell_type": "code",
      "source": [
        "get_weights(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g2anTBElSUjJ",
        "outputId": "e0cc734a-5eec-40ed-cab0-5d19a37337db"
      },
      "id": "g2anTBElSUjJ",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers.0.weight': [[-2.0, 2.0, -2.0, -4.0],\n",
              "  [0.0, 4.0, 0.0, -2.0],\n",
              "  [-4.0, -4.0, -4.0, -2.0],\n",
              "  [4.0, 2.0, 4.0, 4.0],\n",
              "  [-4.0, 4.0, -4.0, -2.0]],\n",
              " 'layers.1.weight': [[2.0, 2.0, -2.0, -2.0, -2.0], [0.0, 0.0, -2.0, 2.0, 0.0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test activations\n",
        "Given an input check each step through the model before and after binaryStep activations."
      ],
      "metadata": {
        "id": "IEpzb3zKQdD6"
      },
      "id": "IEpzb3zKQdD6"
    },
    {
      "cell_type": "code",
      "source": [
        "def step_by_step_output(model, input_data):\n",
        "    act = BinaryStep()\n",
        "    print(\"Input: \", input_data)\n",
        "\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
        "    x = input_tensor\n",
        "\n",
        "    for i, layer in enumerate(model.layers[:-1]):\n",
        "        print(\"##################################\")\n",
        "        # Forward pass through the layer\n",
        "        fc_out = layer(x).detach().cpu().numpy()\n",
        "        t = torch.tensor(fc_out, requires_grad=False)\n",
        "\n",
        "        # Print layer output\n",
        "        print(f\"Output FC{i+1}: \", t)\n",
        "\n",
        "        # Apply activation\n",
        "        fc_out_act = act.apply(t)\n",
        "\n",
        "        # Print activation output\n",
        "        print(f\"After step function FC{i+1}: \", fc_out_act)\n",
        "\n",
        "        # Update x for the next layer\n",
        "        x = fc_out_act\n",
        "\n",
        "    # Handle the last layer separately to apply sigmoid activation\n",
        "    print(\"##################################\")\n",
        "    fc_out = model.layers[-1](x).detach().cpu().numpy()\n",
        "    t = torch.tensor(fc_out, requires_grad=False)\n",
        "    print(f\"Output FC{len(model.layers)}: \", t)\n",
        "    fc_out_act = act.apply(t)\n",
        "    print(f\"After step function FC{len(model.layers)}: \", fc_out_act)"
      ],
      "metadata": {
        "id": "zhLuW6XUQ5D_"
      },
      "id": "zhLuW6XUQ5D_",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input\n",
        "input_data = np.array([[0, 0, 1,1]])  # Adjust dimensions based on your model's input size\n",
        "step_by_step_output(model, input_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nyoqEljGO5lm",
        "outputId": "6d4dee6e-0726-410f-f30c-b35f0902cf5d"
      },
      "id": "nyoqEljGO5lm",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  [[0 0 1 1]]\n",
            "##################################\n",
            "Output FC1:  tensor([[-6., -2., -6.,  8., -6.]])\n",
            "After step function FC1:  tensor([[0., 0., 0., 1., 0.]])\n",
            "##################################\n",
            "Output FC2:  tensor([[-2.,  2.]])\n",
            "After step function FC2:  tensor([[0., 1.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-4b7fc7ecd885>:2: DeprecationWarning: <class '__main__.BinaryStep'> should not be instantiated. Methods on autograd functionsare all static, so you should invoke them on the class itself. Instantiating an autograd function will raise an error in a future version of PyTorch.\n",
            "  act = BinaryStep()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VK_oGA4SmVAo"
      },
      "id": "VK_oGA4SmVAo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}